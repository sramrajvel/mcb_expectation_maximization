{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pset 09: the return of the ten arcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. write a simulator as a positive control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import numpy as np\n",
    "import string\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "# create a function to simulate read counts given tau and length values\n",
    "def simulate(T_i, L_i, N):\n",
    "    counts = 10*[0]\n",
    "    \n",
    "    # create a list of the 10 transcript indices\n",
    "    index = [i for i in range(10)]\n",
    "    \n",
    "    # convert transcript to nucleotide abundances\n",
    "    nu_i = [T_i[i]*L_i[i] for i in range(10)]\n",
    "    nu_i = [i / sum(nu_i) for i in nu_i]\n",
    "    \n",
    "    # loop for desired number of read counts\n",
    "    for j in range(N):\n",
    "        \n",
    "        # choose a transcript with taus as probability distribution\n",
    "        g = np.random.choice(index, p=nu_i)\n",
    "        \n",
    "        # randomly choose a segment present in that transcript\n",
    "        l = np.random.randint(0, L_i[g])\n",
    "        s = index[(g+l) % 10]\n",
    "        \n",
    "        # increment that read count's total\n",
    "        counts[s] += 1\n",
    "        \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128605, 162065, 111215, 76593, 51008, 49216, 90492, 135499, 101172, 94135]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize transcript lengths, random taus, number of read counts\n",
    "L_i = [4, 2, 3, 4, 4, 3, 2, 2, 3, 3]\n",
    "T_i = [np.random.randint(100) for i in range(10)]\n",
    "T_i = [i / sum(T_i) for i in T_i]\n",
    "N = 1000000\n",
    "\n",
    "# generate test dataset\n",
    "sim_counts = simulate(T_i, L_i, N)\n",
    "sim_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. calculate the log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to compute negative log likelihood\n",
    "def nll(counts, T_i, L_i):\n",
    "    \n",
    "    # create list of transcript/segment indicies\n",
    "    index = [i for i in range(10)]\n",
    "    \n",
    "    # calculate nu values from tau values\n",
    "    nu_i = [T_i[i]*L_i[i] for i in range(10)]\n",
    "    nu_i = [i / sum(nu_i) for i in nu_i]\n",
    "    \n",
    "    # create list of lists for the segments present in each transcript\n",
    "    arcs = []\n",
    "    for i in range(10):\n",
    "        \n",
    "        # if transcript is 9 or 10, wrap around the circular arc locus\n",
    "        if i == 8 or i == 9:\n",
    "            s_list = index[i:] + index[0:((i+L_i[i]) % 10)]\n",
    "        else:\n",
    "            s_list = index[i:i+L_i[i]]\n",
    "        arcs.append(s_list)\n",
    "    \n",
    "    # iterate through reads, calculate likelihood\n",
    "    ll_tot = 0\n",
    "    for read_index in range(10):\n",
    "        ll = 0\n",
    "        for gene_index in range(10):\n",
    "            \n",
    "            # if segment present in transcript, compute probability\n",
    "            if read_index in arcs[gene_index]:\n",
    "                ll  += nu_i[gene_index] / L_i[gene_index]\n",
    "        \n",
    "        # multiply by number of counts (adding up log probabilities)\n",
    "        ll_tot += np.log(ll) * counts[read_index]\n",
    "    \n",
    "    return -ll_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lestrade's approach (code taken from pset)\n",
    "\n",
    "def lestrade(counts, T, L):\n",
    "    r = counts\n",
    "    T = 10\n",
    "    S = T    # S = R = T : there are T transcripts (Arc1..Arc10), S segments (A..J), R reads (a..j)\n",
    "    R = T\n",
    "    Slabel   = list(string.ascii_uppercase)[:S]               # ['A'..'J']        : the upper case labels for Arc locus segments \n",
    "    Tlabel   = [ \"Arc{}\".format(d) for d in range(1,T+1) ]    # ['Arc1'..'Arc10'] : the labels for Arc transcript isoforms\n",
    "    Rlabel   = list(string.ascii_lowercase)[:T]               # ['a'..'j']        : lower case labels for reads\n",
    "\n",
    "\n",
    "    # Count how often each segment A..J is used in the isoforms i\n",
    "    # We'll use that to split observed read counts across the isoforms\n",
    "    # that they might have come from.\n",
    "    #\n",
    "    segusage = np.zeros(S).astype(int)\n",
    "    for i in range(T):\n",
    "        for j in range(i,i+L[i]): \n",
    "            segusage[j%S] += 1\n",
    "\n",
    "\n",
    "    # Naive analysis:\n",
    "    #\n",
    "    c  = np.zeros(T)\n",
    "    for i in range(T):\n",
    "        for k in range(i,i+L[i]):\n",
    "            c[i] += (1.0 / float(segusage[k%S])) * float(r[k%S])  # For each read k, assume read k-> segment j,\n",
    "                                                                  # and assign 1/usage count to each transcript\n",
    "                                                                  # that contains segment j.\n",
    "    Z       = np.sum(c)\n",
    "    est_nu  = np.divide(c, Z)       # nucleotide abundance\n",
    "\n",
    "    est_tau = np.divide(est_nu, L)  # convert to TPM, transcript abundance\n",
    "    est_tau = np.divide(est_tau, np.sum(est_tau))\n",
    "        \n",
    "    return est_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lestrade tau estimates:\n",
      "Arc1        0.116\n",
      "Arc2        0.132\n",
      "Arc3        0.077\n",
      "Arc4        0.059\n",
      "Arc5        0.065\n",
      "Arc6        0.071\n",
      "Arc7        0.082\n",
      "Arc8        0.123\n",
      "Arc9        0.136\n",
      "Arc10       0.139\n",
      "\n",
      "true taus:\n",
      "Arc1        0.093\n",
      "Arc2        0.169\n",
      "Arc3        0.040\n",
      "Arc4        0.074\n",
      "Arc5        0.024\n",
      "Arc6        0.034\n",
      "Arc7        0.113\n",
      "Arc8        0.197\n",
      "Arc9        0.076\n",
      "Arc10       0.179\n"
     ]
    }
   ],
   "source": [
    "# run lestrade's appraoch to find his estimated taus\n",
    "est_tau = lestrade(sim_counts, 10, L_i)\n",
    "Tlabel   = [ \"Arc{}\".format(d) for d in range(1,11) ]\n",
    "\n",
    "# print both sets of tau values for comparison\n",
    "print('Lestrade tau estimates:')\n",
    "for i in range(10):\n",
    "    print (\"{0:10s}  {1:5.3f}\".format(Tlabel[i], est_tau[i]))\n",
    "\n",
    "print('\\ntrue taus:')    \n",
    "for i in range(10):\n",
    "    print (\"{0:10s}  {1:5.3f}\".format(Tlabel[i], T_i[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my negative log likelihood: 2090723.9074411509\n",
      "Lestrade's negative log likelihood: 2096553.2595191002\n",
      "difference in log likelihoods: 5829.3520779493265\n"
     ]
    }
   ],
   "source": [
    "# compare negative log likelihoods\n",
    "ll_me = nll(sim_counts, T_i, L_i)\n",
    "ll_lestrade = nll(sim_counts, est_tau, L_i)\n",
    "\n",
    "print('my negative log likelihood:', ll_me)\n",
    "print(\"Lestrade's negative log likelihood:\", ll_lestrade)\n",
    "print('difference in log likelihoods:', ll_lestrade-ll_me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Lestrade's tau value estimates are pretty bad in comparison to the true values. For example, Lestrade predicts Arcs 3 and 9 to have almost twice the probability than they actually do. To further show this, we compute the negative log likelihoods for each set of values. Comparing, we can see that the true taus produce a likelihood almost 6000 smaller than Lestrade's taus, meaning that his parameters are not a great fit for the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. estimate isoform abundances by EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expectation step\n",
    "def expectation(counts, nu_i, L_i):\n",
    "    \n",
    "    # create list of transcript/segment indicies\n",
    "    index = [i for i in range(10)]\n",
    "    \n",
    "    # create list of lists for the segments present in each transcript\n",
    "    arcs = []\n",
    "    for i in range(10):\n",
    "        if i == 8 or i == 9:\n",
    "            s_list = index[i:] + index[0:((i+L_i[i]) % 10)]\n",
    "        else:\n",
    "            s_list = index[i:i+L_i[i]]\n",
    "        arcs.append(s_list)\n",
    "    \n",
    "    # create an i by j array that determines if segment j is in transcript i\n",
    "    # 1 if present, 0 otherwise\n",
    "    in_array = []\n",
    "    for i in range(10):\n",
    "        in_gene = []\n",
    "        for j in range(10):\n",
    "            if j in arcs[i]:\n",
    "                in_gene.append(1)\n",
    "            else:\n",
    "                in_gene.append(0)\n",
    "        in_array.append(in_gene)\n",
    "    \n",
    "    # multiply the element in i, j by the ith nu and 1/length values\n",
    "    # (compute probability of each segment given each transcript)\n",
    "    prob_seq = np.array([[num * nu_i[i] / L_i[i] for num in in_array[i]] for i in range(10)])\n",
    "    \n",
    "    # normalize over all transcripts (sum over columns)\n",
    "    prob_norm = [[prob / sum(prob_seq[:,i]) for prob in prob_seq[:,i]] for i in range(10)]\n",
    "    \n",
    "    # multiply by number of counts and sum for each transcript\n",
    "    exp_counts = [sum([prob_norm[j][i] * counts[j] for j in range (10)]) for i in range (10)]\n",
    "        \n",
    "    return exp_counts\n",
    "\n",
    "\n",
    "# maximization step\n",
    "def maximization(exp_counts):\n",
    "    # convert expected counts to probabilities by dividing by sum\n",
    "    new_nu_i = [count/sum(exp_counts) for count in exp_counts]\n",
    "    return new_nu_i\n",
    "\n",
    "\n",
    "# run EM\n",
    "def EM(counts, L_i):\n",
    "    # initialize random taus, normalize\n",
    "    T_i = [np.random.randint(1, 100) for i in range(10)]\n",
    "    T_i = [i / sum(T_i) for i in T_i]\n",
    "    \n",
    "    # convert taus to nus, normalize\n",
    "    nu_i = [T_i[i]*L_i[i] for i in range(10)]\n",
    "    nu_i = [i / sum(nu_i) for i in nu_i]\n",
    "    \n",
    "    # initialize log likelihood values\n",
    "    old_ll = 0\n",
    "    new_ll = 1\n",
    "    new_nu_i = nu_i\n",
    "    \n",
    "    # run until log likelihood changes by 0.00001 or less\n",
    "    while abs(new_ll-old_ll) > 0.00001:\n",
    "        \n",
    "        # run expectation, then maximization to update nus\n",
    "        exp_counts = expectation(counts,new_nu_i,L_i)\n",
    "        new_nu_i = maximization(exp_counts)\n",
    "        \n",
    "        # compute taus from nus to calculate log likelihood\n",
    "        tau_i = [new_nu_i[i] / L_i[i] for i in range(10)]\n",
    "        tau_i = [tau / sum(tau_i) for tau in tau_i]\n",
    "        old_ll = new_ll\n",
    "        new_ll = nll(counts,tau_i,L_i)  \n",
    "    \n",
    "    return new_ll, tau_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my tau estimates:\n",
      "Arc1       0.1414689644906891\n",
      "Arc2       0.019259730963126224\n",
      "Arc3       0.08436879588987034\n",
      "Arc4       0.05277139327728457\n",
      "Arc5       0.022906837918719985\n",
      "Arc6       0.1634626848002875\n",
      "Arc7       0.31249812260394344\n",
      "Arc8       0.09545045743603983\n",
      "Arc9       0.07548779053274306\n",
      "Arc10      0.03232522208729613\n"
     ]
    }
   ],
   "source": [
    "# run EM on counts data given in pset, print tau estimates\n",
    "L_i = [4, 2, 3, 4, 4, 3, 2, 2, 3, 3]\n",
    "data_counts = [89357,69196,87852,99854,57369,85715,197730,213016,61271,38640]\n",
    "\n",
    "best_ll, best_tau = EM(data_counts, L_i)\n",
    "\n",
    "print('my tau estimates:')\n",
    "for i in range(10):\n",
    "    print(\"{0:10s}\".format(Tlabel[i]), best_tau[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lestrade tau estimates:\n",
      "Arc1        0.062\n",
      "Arc2        0.051\n",
      "Arc3        0.098\n",
      "Arc4        0.143\n",
      "Arc5        0.153\n",
      "Arc6        0.157\n",
      "Arc7        0.148\n",
      "Arc8        0.097\n",
      "Arc9        0.048\n",
      "Arc10       0.044\n"
     ]
    }
   ],
   "source": [
    "# run lestrade's method on same data, print tau estimates\n",
    "les_tau = lestrade(data_counts, 10, L_i)\n",
    "les_ll = nll(data_counts, les_tau, L_i)\n",
    "\n",
    "print('Lestrade tau estimates:')\n",
    "for i in range(10):\n",
    "    print (\"{0:10s}  {1:5.3f}\".format(Tlabel[i], est_tau[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my negative log likelihood: 2165610.3540291633\n",
      "Lestrade's negative log likelihood: 2190089.552613845\n",
      "difference in log likelihoods: 24479.198584681842\n"
     ]
    }
   ],
   "source": [
    "# compare negative log likelihoods\n",
    "print('my negative log likelihood:', best_ll)\n",
    "print(\"Lestrade's negative log likelihood:\", les_ll)\n",
    "print('difference in log likelihoods:', les_ll-best_ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lestrade's conclusion that all 10 mRNA transcripts are expressed at the same level seems incorrect. Using EM, we have calculated transcript abundance values that produce a smaller log likelihood value (by roughly 25000), meaning they are much closer to the true values. The two most abundant transcripts are Arcs 6 and 7, which account for almost half of the population. The two least abundant transcripts are Arcs 2 and 5, which account for less than 5% of the population.\n",
    "\n",
    "Intuitively, Lestrade's method doesn't seem to be as accurate, since it assumes each read maps to the transcripts in which it could be found with equal probability. However, this doesn't take into account that the transcript abundance values should influence the probability a certain read belongs to a certain transcript. Thus, it makes sense that EM produces better estimates. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
